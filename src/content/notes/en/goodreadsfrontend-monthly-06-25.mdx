---
title: 'Frontend Good Reads – June 2025'
publishingDate: 2025-07-01
description: 'A monthly Frontend Good Reads digest: ChatGPT personalization, Cache-Control request header'
---

A monthly digest from my telegram channel **[Frontend Good Reads](https://t.me/goodreadsfrontend)** where I share interesting articles, videos, and news from the frontend world and my thoughts about them. Sometimes there are some offtopics: UX, learning, technologies, etc.

## My experience using ChatGPT with enabled personalization

I have been trying to use ChatGPT with enabled personalization for several weeks.

For the first week it seemed convenient: you don't need to specify some of the system's feature are constraints explicitly.

But during the second week I began feeling an obvious decrease in the responses quality, like the whole context about me got mixed up and was trying to being used, adding more and more details in there. As a result, the average response quality had decreased dramatically and I had to specify the context every each time.

Maybe there are ways to manage this kind of personalization, but I decided to just turn it off several days ago, and the responses quality improved rapidly.

There is an article written by Addy Osmani on this topic [The Prompt Engineering Playbook for Programmers](https://addyo.substack.com/p/the-prompt-engineering-playbook-for). He writes in very beautiful language, but there is a fair amount of fluff. I will just highlight the following principles:

- **Provide the AI exhaustive context.** Imagine that AI doesn't know anything about the project except what you have told it, (that’s really the case if the context is turned off).
- **Be concrete about your goals and questions.** Vague questions lead to vague answers.
- **Split complex tasks.** Begin with high-level goals and iteratively ask about its different parts.
- **Provide examples of input/output or examples of desired results.** It helps the AI to understand your intentions better and avoid misunderstandings.
- **Use roles.** It can affect the depth and style of a response. Example: `You are a senior {language} developer. Review this function for {goal}.`.
- **Improve the dialogue iteratively.** AI remembers the history of the chat, so it can gradually adjust it (for me, a prompt change with the clear context works better, if the response is quite far from the desired one).
- **Keep code consistent and clear.** Meaningful function names and variables, consistent formatting, and suitable comments are helpful not only for humans to understand the code, but also to optimize the AI work with it.

## Couple words about Cache-Control request header

**[Why Do We Have a Cache-Control Request Header?](https://csswizardry.com/2025/03/why-do-we-have-a-cache-control-request-header/)**

If everything is quite clear about using the `Cache-Control` header in the response, using it for a request is not obvious at all. Never thought about it from that perspective.

It instructs the CDN or server to revalidate the cache for this request. `max-age=0` – request revalidation, `no-cache` – request revalidation more insistently and forbid returning a response without it.

There are several cases to use it:

- Used by browsers for normal and hard page reloads, and as we all love, every of the three major browsers (Chrome, Safari, Firefox) behaves differently in these scenarios.
- Can be added to requests, whose responses are very desirable to be up-to-date. In addition to the correct server response headers for reliability or if we do not trust it.
- And the most interesting case is about offline applications: with the value `only-if-cached`, so as not to make a request to the network, but only try to get the response from the cache.
